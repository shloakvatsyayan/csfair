{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Note, requires pytorch and ultralytics packages:\n",
    "- https://github.com/ultralytics/ultralytics\n",
    "- https://pytorch.org/get-started/locally/"
   ],
   "id": "3ecc14ce87ce64"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "current_tracked_box = None\n",
    "current_frame_boxes = []\n",
    "is_person_selected = False\n",
    "iou_threshold_value = 0.3\n",
    "direction_definitions = [\"right\", \"left\"]"
   ],
   "id": "3f1fe5cd956806e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "model yolov11, v8 might be useful",
   "id": "85c1707136fc808b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = YOLO(\"yolo11n.pt\")\n",
    "model.to(\"cuda\") #comment this line out if not using an nvidia gpu"
   ],
   "id": "4a0578f5d55d2a6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "camera_stream = cv2.VideoCapture(0)\n",
    "camera_stream.set(cv2.CAP_PROP_FRAME_WIDTH, 1200)\n",
    "camera_stream.set(cv2.CAP_PROP_FRAME_HEIGHT, 1000)"
   ],
   "id": "24ca2e9ba2803807",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_iou(bounding_box_a, bounding_box_b):\n",
    "    xA = max(bounding_box_a[0], bounding_box_b[0])\n",
    "    yA = max(bounding_box_a[1], bounding_box_b[1])\n",
    "    xB = min(bounding_box_a[2], bounding_box_b[2])\n",
    "    yB = min(bounding_box_a[3], bounding_box_b[3])\n",
    "    intersection_width = max(0, xB - xA)\n",
    "    intersection_height = max(0, yB - yA)\n",
    "    intersection_area = intersection_width * intersection_height\n",
    "    area_a = (bounding_box_a[2] - bounding_box_a[0]) * (bounding_box_a[3] - bounding_box_a[1])\n",
    "    area_b = (bounding_box_b[2] - bounding_box_b[0]) * (bounding_box_b[3] - bounding_box_b[1])\n",
    "    return intersection_area / (area_a + area_b - intersection_area + 1e-6)"
   ],
   "id": "d00f96e3bfc52a9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def handle_mouse_click(event, mouse_x, mouse_y, flags, param):\n",
    "    global current_tracked_box\n",
    "    global is_person_selected\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        for (box_x1, box_y1, box_x2, box_y2) in current_frame_boxes:\n",
    "            if box_x1 <= mouse_x <= box_x2 and box_y1 <= mouse_y <= box_y2:\n",
    "                current_tracked_box = (box_x1, box_y1, box_x2, box_y2)\n",
    "                is_person_selected = True\n",
    "                print(\"Selected new person for tracking:\", current_tracked_box)\n",
    "                return\n",
    "        current_tracked_box = None\n",
    "        is_person_selected = False\n",
    "        print(\"No person clicked. Tracking disabled.\")"
   ],
   "id": "26a66a91fdc6de7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cv2.namedWindow(\"Webcam\")\n",
    "cv2.setMouseCallback(\"Webcam\", handle_mouse_click)\n",
    "\n",
    "while True:\n",
    "    ret, frame = camera_stream.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    current_frame_boxes = []\n",
    "    predictions = model.predict(\n",
    "        source=frame,\n",
    "        stream=True,\n",
    "        verbose=False\n",
    "    )\n",
    "    for prediction in predictions:\n",
    "        for bounding_box in prediction.boxes:\n",
    "            if int(bounding_box.cls[0]) == 0:\n",
    "                x1, y1, x2, y2 = map(int, bounding_box.xyxy[0])\n",
    "                current_frame_boxes.append((x1, y1, x2, y2))\n",
    "    if is_person_selected and current_tracked_box:\n",
    "        best_iou_score = 0.0\n",
    "        best_box_match = None\n",
    "        for box in current_frame_boxes:\n",
    "            iou_value = calculate_iou(current_tracked_box, box)\n",
    "            if iou_value > best_iou_score:\n",
    "                best_iou_score = iou_value\n",
    "                best_box_match = box\n",
    "        if best_box_match and best_iou_score >= iou_threshold_value:\n",
    "            current_tracked_box = best_box_match\n",
    "        else:\n",
    "            print(\"Lost track (no matching box over IOU threshold).\")\n",
    "            current_tracked_box = None\n",
    "            is_person_selected = False\n",
    "    for (box_x1, box_y1, box_x2, box_y2) in current_frame_boxes:\n",
    "        rectangle_color = (255, 0, 255)\n",
    "        rectangle_thickness = 2\n",
    "        if is_person_selected and current_tracked_box and (box_x1, box_y1, box_x2, box_y2) == current_tracked_box:\n",
    "            rectangle_color = (0, 255, 0)\n",
    "            rectangle_thickness = 3\n",
    "        cv2.rectangle(frame, (box_x1, box_y1), (box_x2, box_y2), rectangle_color, rectangle_thickness)\n",
    "    if is_person_selected and current_tracked_box:\n",
    "        tracked_x1, tracked_y1, tracked_x2, tracked_y2 = current_tracked_box\n",
    "        person_center_x = (tracked_x1 + tracked_x2) // 2\n",
    "        frame_center_x = frame.shape[1] // 2\n",
    "        if person_center_x > frame_center_x:\n",
    "            direction_index = 0\n",
    "        else:\n",
    "            direction_index = 1\n",
    "        print(direction_definitions[direction_index])\n",
    "    cv2.imshow(\"Webcam\", frame)\n",
    "    key_pressed = cv2.waitKey(1)\n",
    "    if key_pressed & 0xFF == ord('q'):\n",
    "        break\n",
    "camera_stream.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "516619fd7bc3667",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#use in case of keyboard interrupt to remove window\n",
    "camera_stream.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "f58a5f5e0d67b31f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "57a9fae1168765ab",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
